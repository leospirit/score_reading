"""
å£è¯­è¯„åˆ† CLI æ¡†æ¶ - HTML æŠ¥å‘Šæ¸²æŸ“æ¨¡å—

è´Ÿè´£å°†è¯„åˆ†ç»“æœæ¸²æŸ“ä¸º HTML æŠ¥å‘Šã€‚
æ”¯æŒéŸ³é¢‘æ³¢å½¢åµŒå…¥å’Œäº¤äº’æ’­æ”¾ã€‚
"""
import base64
import logging
from pathlib import Path
from typing import Any

from jinja2 import Environment, FileSystemLoader

from src.config import config
from src.models import ScoringResult

logger = logging.getLogger(__name__)

# æ¨¡æ¿ç›®å½•
TEMPLATES_DIR = Path(__file__).parent / "templates"

# å‘éŸ³æŒ‡å¯¼è§„åˆ™
PHONEME_TIPS = {
    "Î¸": {
        "name": "æ— å£°é½¿æ“¦éŸ³",
        "examples": ["three", "think", "thank"],
        "advice": "èˆŒå°–è½»è§¦ä¸Šé½¿ï¼Œæ°”æµä»èˆŒå°–ä¸ä¸Šé½¿é—´éš™ä¸­é€šè¿‡ã€‚å¯ä»¥ç”¨é•œå­æ£€æŸ¥èˆŒå°–æ˜¯å¦å¯è§ã€‚"
    },
    "Ã°": {
        "name": "æœ‰å£°é½¿æ“¦éŸ³",
        "examples": ["the", "this", "that"],
        "advice": "ä¸ /Î¸/ ç›¸ä¼¼ï¼Œä½†éœ€è¦æŒ¯åŠ¨å£°å¸¦ã€‚èˆŒå°–è½»è§¦ä¸Šé½¿ï¼ŒåŒæ—¶å‘å‡º'å—¡å—¡'å£°ã€‚"
    },
    "r": {
        "name": "å·èˆŒéŸ³",
        "examples": ["red", "run", "right"],
        "advice": "èˆŒå°–å‘åå·æ›²ï¼Œä¸è¦æ¥è§¦å£è…”ä»»ä½•éƒ¨ä½ã€‚å˜´å”‡ç•¥å¾®åœ†èµ·ã€‚"
    },
    "l": {
        "name": "èˆŒè¾¹éŸ³",
        "examples": ["like", "love", "light"],
        "advice": "èˆŒå°–é¡¶ä½ä¸Šé½¿é¾ˆï¼Œæ°”æµä»èˆŒå¤´ä¸¤ä¾§é€šè¿‡ã€‚ç»“å°¾çš„ /l/ éœ€è¦æŠŠèˆŒå°–é¡¶ä½ï¼Œä¸è¦çœç•¥ã€‚"
    },
    "v": {
        "name": "å”‡é½¿æ“¦éŸ³",
        "examples": ["very", "have", "love"],
        "advice": "ä¸Šé½¿è½»è½»å’¬ä½ä¸‹å”‡ï¼ŒæŒ¯åŠ¨å£°å¸¦ã€‚æ³¨æ„ä¸è¦å‘æˆ /w/ã€‚"
    },
    "w": {
        "name": "åœ†å”‡åŠå…ƒéŸ³",
        "examples": ["we", "what", "water"],
        "advice": "å˜´å”‡æ”¶åœ†ï¼Œåƒå¹å£å“¨çš„å˜´å½¢ï¼Œç„¶åå¿«é€Ÿè¿‡æ¸¡åˆ°åé¢çš„å…ƒéŸ³ã€‚"
    },
    "Å‹": {
        "name": "åé¼»éŸ³",
        "examples": ["sing", "thing", "king"],
        "advice": "èˆŒæ ¹æŠ¬èµ·æ¥è§¦è½¯è…­ï¼Œæ°”æµä»é¼»è…”é€šè¿‡ã€‚ä¸è¦åœ¨ç»“å°¾åŠ  /g/ çš„éŸ³ã€‚"
    },
    "Ã¦": {
        "name": "å¼€å‰å…ƒéŸ³",
        "examples": ["cat", "bad", "apple"],
        "advice": "å˜´å·´å¼ å¤§ï¼ŒèˆŒå¤´æ”¾å¹³å¹¶å°½é‡å¾€å‰ï¼Œå˜´è§’ç•¥å¾®æ‹‰å¼€ã€‚æ¯”ä¸­æ–‡çš„'å•Š'å˜´å·´å¼ å¾—æ›´å¤§ã€‚"
    },
}


def encode_audio_base64(audio_path: Path) -> str | None:
    """
    å°†éŸ³é¢‘æ–‡ä»¶ç¼–ç ä¸º base64
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        base64 ç¼–ç å­—ç¬¦ä¸²ï¼Œæˆ– Noneï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰
    """
    if not audio_path or not audio_path.exists():
        return None
    
    try:
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        return base64.b64encode(audio_data).decode("utf-8")
    except Exception as e:
        logger.warning(f"æ— æ³•ç¼–ç éŸ³é¢‘æ–‡ä»¶: {e}")
        return None


def get_phoneme_tips(weak_phonemes: list[str]) -> list[dict[str, Any]]:
    """
    æ ¹æ®å¼±éŸ³ç´ åˆ—è¡¨è·å–å‘éŸ³æŒ‡å¯¼
    
    Args:
        weak_phonemes: å¼±éŸ³ç´ åˆ—è¡¨
        
    Returns:
        å‘éŸ³æŒ‡å¯¼åˆ—è¡¨
    """
    tips = []
    seen = set()
    
    for phoneme in weak_phonemes:
        # æ¸…ç†éŸ³ç´ ç¬¦å·
        clean_phoneme = phoneme.strip("/[]").lower()
        
        # æŸ¥æ‰¾åŒ¹é…çš„æŒ‡å¯¼
        for key, tip in PHONEME_TIPS.items():
            if key.lower() in clean_phoneme or clean_phoneme in key.lower():
                if key not in seen:
                    tips.append({
                        "phoneme": key,
                        "name": tip["name"],
                        "examples": tip["examples"],
                        "advice": tip["advice"],
                    })
                    seen.add(key)
    
    return tips


def generate_pronunciation_analysis(
    weak_words: list[str],
    weak_phonemes: list[str],
    phoneme_alignments: list[dict[str, Any]] | None = None,
) -> list[dict[str, Any]]:
    """
    ç”Ÿæˆå‘éŸ³é—®é¢˜åˆ†ææ•°æ®
    
    å½“æœ‰è¯¦ç»†çš„éŸ³ç´ å¯¹é½æ•°æ®æ—¶ï¼ŒåŸºäºè¯¥æ•°æ®ç”Ÿæˆåˆ†æï¼›
    å¦åˆ™åŸºäº weak_phonemes å’Œ weak_words ç”Ÿæˆåˆ†æã€‚
    
    Args:
        weak_words: å¼±è¯åˆ—è¡¨
        weak_phonemes: å¼±éŸ³ç´ åˆ—è¡¨
        phoneme_alignments: éŸ³ç´ å¯¹é½æ•°æ®ï¼ˆåŒ…å« in_word å­—æ®µï¼‰
        
    Returns:
        å‘éŸ³é—®é¢˜åˆ†æåˆ—è¡¨ï¼Œç”¨äºæ¨¡æ¿æ¸²æŸ“
    """
    analysis = []
    
    # æ‰©å±•çš„éŸ³ç´ ä¿¡æ¯æ˜ å°„ï¼ˆåŒ…æ‹¬å¤§å°å†™å˜ä½“ï¼‰
    phoneme_tips_extended = {
        # åŸå§‹é”®
        **PHONEME_TIPS,
        # å°å†™å˜ä½“
        "Ã¦": PHONEME_TIPS.get("Ã¦", {"name": "å¼€å‰å…ƒéŸ³ Ã¦", "advice": "å˜´å·´å¼ å¤§ï¼ŒèˆŒå¤´æ”¾å¹³å¹¶å¾€å‰ã€‚"}),
        "É›": {"name": "ä¸­å‰å…ƒéŸ³ É›", "advice": "å˜´å·´åŠå¼€ï¼ŒèˆŒå¤´ä¸­ä½é å‰ã€‚ç±»ä¼¼ä¸­æ–‡'è¯¶'ä½†æ›´æ”¾æ¾ã€‚"},
        "Éª": {"name": "çŸ­å…ƒéŸ³ Éª", "advice": "å˜´å·´å¾®å¼€ï¼ŒèˆŒå¤´é«˜ä½é å‰ã€‚ç±»ä¼¼ä¸­æ–‡'è¡£'ä½†æ›´çŸ­ä¿ƒã€‚"},
        "É”": {"name": "ä¸­åå…ƒéŸ³ É”", "advice": "å˜´å·´åŠå¼€ï¼ŒèˆŒå¤´ä¸­ä½é åã€‚ç±»ä¼¼ä¸­æ–‡'å“¦'ä½†å˜´å‹æ›´åœ†ã€‚"},
        # å¤§å†™å˜ä½“ï¼ˆç”¨äºåŒ¹é… Whisper è¾“å‡ºï¼‰
        "Ã†": {"name": "å¼€å‰å…ƒéŸ³ Ã¦", "advice": "å˜´å·´å¼ å¤§ï¼ŒèˆŒå¤´æ”¾å¹³å¹¶å¾€å‰ã€‚"},
        "Æ": {"name": "ä¸­å‰å…ƒéŸ³ É›", "advice": "å˜´å·´åŠå¼€ï¼ŒèˆŒå¤´ä¸­ä½é å‰ã€‚ç±»ä¼¼ä¸­æ–‡'è¯¶'ä½†æ›´æ”¾æ¾ã€‚"},
    }
    
    # 1. ä¼˜å…ˆä½¿ç”¨è¯¦ç»†çš„éŸ³ç´ å¯¹é½æ•°æ®
    if phoneme_alignments:
        # æŒ‰éŸ³ç´ åˆ†ç»„
        phoneme_groups: dict[str, list[str]] = {}
        for pa in phoneme_alignments:
            phoneme = pa.get("phoneme", "")
            in_word = pa.get("in_word", "")
            if phoneme and in_word:
                if phoneme not in phoneme_groups:
                    phoneme_groups[phoneme] = []
                if in_word not in phoneme_groups[phoneme]:
                    phoneme_groups[phoneme].append(in_word)
        
        # ä¸ºæ¯ä¸ªéŸ³ç´ ç”Ÿæˆåˆ†æ
        for phoneme, words in list(phoneme_groups.items())[:3]:
            phoneme_info = phoneme_tips_extended.get(phoneme) or phoneme_tips_extended.get(phoneme.lower())
            if phoneme_info:
                analysis.append({
                    "target": phoneme,
                    "name": phoneme_info.get("name", f"éŸ³ç´  {phoneme}"),
                    "mistakes": [{
                        "actual": "å‘éŸ³éœ€æ”¹è¿›",
                        "desc": phoneme_info.get("advice", "æ³¨æ„å‘éŸ³ä½ç½®å’Œæ°”æµæ§åˆ¶ã€‚"),
                        "words": [{"text": w, "ipa": f"/{phoneme}/"} for w in words[:4]],
                    }],
                })
    
    # 2. å¦‚æœæ²¡æœ‰è¯¦ç»†æ•°æ®ï¼Œä½¿ç”¨ weak_phonemes åˆ—è¡¨
    if not analysis and weak_phonemes:
        for phoneme in weak_phonemes[:3]:
            # å°è¯•åŒ¹é…éŸ³ç´ ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            phoneme_info = phoneme_tips_extended.get(phoneme) or phoneme_tips_extended.get(phoneme.lower())
            if phoneme_info:
                # æ‰¾å‡ºå¯èƒ½ç›¸å…³çš„å¼±è¯
                related_words = []
                for word in weak_words:
                    related_words.append({"text": word, "ipa": f"/{phoneme}/"})
                    if len(related_words) >= 4:
                        break
                
                analysis.append({
                    "target": phoneme,
                    "name": phoneme_info.get("name", f"éŸ³ç´  {phoneme}"),
                    "mistakes": [{
                        "actual": "å‘éŸ³éœ€ç»ƒä¹ ",
                        "desc": phoneme_info.get("advice", "æ³¨æ„å‘éŸ³ä½ç½®å’Œæ°”æµæ§åˆ¶ã€‚"),
                        "words": related_words if related_words else [{"text": "(æ— ç¤ºä¾‹è¯)", "ipa": ""}],
                    }],
                })
    
    # 3. æœ€åå›é€€ï¼šå¦‚æœæ²¡æœ‰éŸ³ç´ åˆ†æä½†æœ‰å¼±è¯
    if not analysis and weak_words:
        # å°è¯•ä»å¼±è¯ä¸­æå–ä¸€äº›å¸¸è§çš„éŸ³ç´ æŒ‘æˆ˜ï¼ˆç®€å•è§„åˆ™ï¼‰
        challenges = []
        for word in weak_words:
            w_lower = word.lower()
            if 'th' in w_lower: challenges.append("Î¸/Ã°")
            if 'v' in w_lower: challenges.append("v")
            if 'l' in w_lower: challenges.append("l")
            if 'r' in w_lower: challenges.append("r")
            if 'ng' in w_lower: challenges.append("Å‹")
        
        # æå–ç‹¬ç‰¹çš„æŒ‘æˆ˜
        unique_challenges = list(dict.fromkeys(challenges))[:2]
        challenge_desc = f"é‡ç‚¹å…³æ³¨éŸ³ç´ : {', '.join(unique_challenges)}" if unique_challenges else "æ•´ä½“å‘éŸ³æ¸…æ™°åº¦"

        analysis.append({
            "target": "ğŸ“–",
            "name": "é‡ç‚¹è¯æ±‡ç»ƒä¹ ",
            "is_fallback": True,
            "mistakes": [{
                "actual": challenge_desc,
                "desc": "ä»¥ä¸‹å•è¯çš„å‘éŸ³å¾—åˆ†è¾ƒä½ï¼Œå»ºè®®åå¤è·Ÿè¯»ï¼Œç‰¹åˆ«æ³¨æ„å…ƒéŸ³çš„é¥±æ»¡åº¦å’Œè¾…éŸ³çš„æ¸…æ™°åº¦ã€‚",
                "words": [{"text": w, "ipa": ""} for w in weak_words[:5]],
            }],
        })
    
    return analysis


def render_html_report(
    result: ScoringResult,
    output_path: Path,
    audio_path: Path | None = None,
) -> None:
    """
    æ¸²æŸ“ HTML æŠ¥å‘Š
    
    Args:
        result: è¯„åˆ†ç»“æœ
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåµŒå…¥æ’­æ”¾ï¼‰
    """
    logger.info(f"å¼€å§‹æ¸²æŸ“ HTML æŠ¥å‘Š: {output_path}")
    
    # åŠ è½½æ¨¡æ¿
    env = Environment(
        loader=FileSystemLoader(str(TEMPLATES_DIR)),
        autoescape=True,
    )
    template = env.get_template("report.html.j2")
    
    # è·å–é¢œè‰²é…ç½®
    colors = {
        "ok": config.get("report.colors.ok", "#4CAF50"),
        "weak": config.get("report.colors.weak", "#FFC107"),
        "missing": config.get("report.colors.missing", "#F44336"),
        "poor": config.get("report.colors.poor", "#E91E63"),
    }
    
    # å‡†å¤‡æ¨¡æ¿æ•°æ®
    # å°† WordAlignment è½¬æ¢ä¸ºæ¨¡æ¿å¯ç”¨çš„å­—å…¸æ ¼å¼ï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œé«˜çº§å±æ€§ï¼‰
    alignment_words = []
    for word in result.alignment.words:
        word_data = {
            "word": word.word,
            "score": word.score,
            "tag": word.tag.value,
            "start": word.start,
            "end": word.end,
            "stress": word.stress,
            "expected_stress": word.expected_stress,
            "is_linked": word.is_linked,
        }
        # å¦‚æœå­˜åœ¨ Pause ä¿¡æ¯ï¼Œè½¬æ¢ä¸ºå­—å…¸
        if word.pause:
            word_data["pause"] = {
                "type": word.pause.type, # å‡è®¾æ˜¯å­—ç¬¦ä¸²æˆ– Enum.value
                "duration": word.pause.duration
            }
        alignment_words.append(word_data)
    
    # ç¼–ç éŸ³é¢‘ä¸º base64
    audio_base64 = encode_audio_base64(audio_path) if audio_path else None
    
    # è·å–å‘éŸ³æŒ‡å¯¼
    phoneme_tips = get_phoneme_tips(result.analysis.weak_phonemes or [])
    
    # æå– Hesitations æ•°æ®
    hesitations_data = None
    if result.analysis.hesitations:
        hesitations_data = {
            "score_label": result.analysis.hesitations.score_label,
            "desc": result.analysis.hesitations.desc,
            "fillers": result.analysis.hesitations.fillers,
            "examples": result.analysis.hesitations.examples,
            "tips": result.analysis.hesitations.tips
        }
        
    # æå– Completeness æ•°æ®
    completeness_data = None
    if result.analysis.completeness:
        completeness_data = {
            "title": result.analysis.completeness.title,
            "score_label": result.analysis.completeness.score_label,
            "coverage": result.analysis.completeness.coverage,
            "missing_stats": result.analysis.completeness.missing_stats,
            "insight": result.analysis.completeness.insight,
            "tips": result.analysis.completeness.tips
        }

    # æå– Pace Chart æ•°æ®
    pace_chart_data = [{"x": p.x, "y": p.y} for p in result.analysis.pace_chart_data]

    template_data = {
        "meta": {
            "task_id": result.meta.task_id,
            "student_id": result.meta.student_id,
            "student_name": result.meta.student_name,
            "submission_id": result.meta.submission_id,
            "timestamp": result.meta.timestamp,
            "engine_used": result.meta.engine_used,
        },
        "scores": {
            "overall_100": result.scores.overall_100,
            "pronunciation_100": result.scores.pronunciation_100,
            "fluency_100": result.scores.fluency_100,
            "intonation_100": result.scores.intonation_100,
            "completeness_100": result.scores.completeness_100,
        },
        "alignment": {
            "words": alignment_words,
        },
        "analysis": {
            "weak_words": result.analysis.weak_words,
            "weak_phonemes": result.analysis.weak_phonemes,
            "missing_words": result.analysis.missing_words,
            "mistakes": result.analysis.mistakes,
        },
        "pronunciation_analysis": generate_pronunciation_analysis(
            result.analysis.weak_words,
            result.analysis.weak_phonemes,
            [p.to_dict() if hasattr(p, "to_dict") else vars(p) for p in result.alignment.phonemes]
        ),
        "hesitations": hesitations_data,
        "completeness_analysis": completeness_data,
        "pace_chart_data": pace_chart_data,
        "pitch_contour": [{"t": p.t, "f": p.f0} for p in result.analysis.pitch_contour],
        "feedback": {
            "cn_summary": result.feedback.cn_summary,
            "cn_actions": result.feedback.cn_actions,
            "practice": result.feedback.practice,
        },
        "feedback": {
            "cn_summary": result.feedback.cn_summary,
            "cn_actions": result.feedback.cn_actions,
            "practice": result.feedback.practice,
        },
        "advisor_feedback": result.advisor_feedback,
        "colors": colors,
        "audio_base64": audio_base64,
        "phoneme_tips": phoneme_tips,
        "pronunciation_analysis": generate_pronunciation_analysis(
            result.analysis.weak_words or [],
            result.analysis.weak_phonemes or [],
            [{"phoneme": p.phoneme, "in_word": p.in_word, "score": p.score} 
             for p in result.alignment.phonemes] if result.alignment.phonemes else None,
        ),
        "engine_raw": result.engine_raw,
        # ä¼˜å…ˆä½¿ç”¨éŸ³é¢‘æ–‡ä»¶åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨è¾“å‡ºæ–‡ä»¶åï¼Œæœ€åå›é€€åˆ° unknown
        "audio_stem": audio_path.stem if audio_path else (output_path.stem if output_path else "Unknown"),
    }
    
    # æ¸²æŸ“ HTML
    html_content = template.render(**template_data)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å†™å…¥æ–‡ä»¶
    output_path.write_text(html_content, encoding="utf-8")
    
    logger.info(f"HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


def regenerate_report_from_json(json_path: Path, output_path: Path) -> None:
    """
    ä» JSON æ–‡ä»¶é‡æ–°ç”Ÿæˆ HTML æŠ¥å‘Š
    
    Args:
        json_path: JSON ç»“æœæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡º HTML æ–‡ä»¶è·¯å¾„
    """
    import json
    
    if not json_path.exists():
        raise FileNotFoundError(f"JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
    
    # åŠ è½½ JSON
    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)
    
    # åŠ è½½æ¨¡æ¿
    env = Environment(
        loader=FileSystemLoader(str(TEMPLATES_DIR)),
        autoescape=True,
    )
    template = env.get_template("report.html.j2")
    
    # è·å–é¢œè‰²é…ç½®
    colors = {
        "ok": config.get("report.colors.ok", "#4CAF50"),
        "weak": config.get("report.colors.weak", "#FFC107"),
        "missing": config.get("report.colors.missing", "#F44336"),
        "poor": config.get("report.colors.poor", "#E91E63"),
    }
    
    # æ·»åŠ é¢œè‰²åˆ°æ•°æ®
    data["colors"] = colors
    
    # è·å–å‘éŸ³æŒ‡å¯¼
    weak_phonemes = data.get("analysis", {}).get("weak_phonemes", [])
    data["phoneme_tips"] = get_phoneme_tips(weak_phonemes or [])
    
    # ç¡®ä¿æ²¡æœ‰ audio_base64ï¼ˆä» JSON é‡æ–°ç”Ÿæˆæ—¶ä¸åµŒå…¥éŸ³é¢‘ï¼‰
    if "audio_base64" not in data:
        data["audio_base64"] = None

    # ç¡®ä¿ advisor_feedback å­˜åœ¨
    if "advisor_feedback" not in data:
        data["advisor_feedback"] = None

    # ç¡®ä¿ engine_raw å­˜åœ¨ (è§£å†³ UndefinedError)
    if "engine_raw" not in data:
        data["engine_raw"] = {}
    
    # æ¸²æŸ“ HTML
    html_content = template.render(**data)
    
    # å†™å…¥æ–‡ä»¶
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(html_content, encoding="utf-8")
    
    logger.info(f"HTML æŠ¥å‘Šå·²é‡æ–°ç”Ÿæˆ: {output_path}")

